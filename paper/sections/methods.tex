\section{Methods}

\subsection{$\mathDeePWAK$}

Our basic unit performing clustering is the \DeePWAK head.
It is a deep learning architecture consisting of an encoder, partitioner, and decoder subnetworks.
%Details are in Appendix \ref{app:DeePWAK}.


\begin{figure}
     \begin{subfigure}[b]{0.5\textwidth}
        \input{tikz/DeePWAK.tex}
         \caption{}
         \label{fig:}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{\textwidth}
        \input{tikz/DeePWAKBlock.tex}
         \caption{}
         \label{fig:}
     \end{subfigure}

     \caption{
       (a) Architecture of one DeePWAK head.
       (b) Architecture of one DeePWAK block with $h=5$.}
     \label{fig:}
\end{figure}
  
\subsection{Ensemble $\mathDeePWAK$}

\DeePWAK can be used for ensemble clustering by training multiple heads in parallel and linearly combining the results. We refer to this as a \DeePWAKBlock.

After training the \DeePWAKBlock, we can attempt to learn pooling models that compute consensus clusters and embeddings (Fig. \ref{fig:consensus} Appendix \ref{app:consenus}).

\begin{figure}
     \begin{subfigure}[b]{0.5\textwidth}
        \input{tikz/consensusencoder.tex}
         \caption{}
         \label{fig:}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{\textwidth}
       \input{tikz/consensus.tex}
       \caption{}
       \label{fig:consenus}
     \end{subfigure}

  \vspace{1cm}
     
     \begin{subfigure}[b]{0.5\textwidth}
       \input{tikz/DeePWAK_Ec.tex}
         \caption{}
         \label{fig:}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.5\textwidth}
        \input{tikz/DeePWAK_Cc.tex}
         \caption{}
         \label{fig:}
     \end{subfigure}

     \caption{(a,b) Calculation of consensus $E$ and $C$, respectively.
     (c,d) Drop-in of consensus $E$ and $C$.}
     \label{fig:}
\end{figure}

\subsection{Recurrent DeePWAK}
