\documentclass{article}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}

\usepackage{algorithm2e}


\usepackage{authblk}

\usepackage[backend=biber]{biblatex}
\addbibresource{refs.bib}

\graphicspath{ {./fig/} }

\usepackage{tikz}
\usetikzlibrary{arrows.meta, bending, positioning}

\input{mathops.tex}

\date{\today}

\title{Denoising with a Partitioned Affinity Kernel Enables Cluster-Feature Decomposition}

\author[1]{Keira Wiechecki}
\author[2]{Jade Zaslavsky}
\affil[1]{Center for Genomics \& Systems Biology, New York University \\
  \texttt{kaw504@nyu.edu}}
\affil[2]{Transcribbit}

\begin{document}
\maketitle

\begin{abstract}
  We introduce a new method of deep clustering using denoising.
  A denoising prior allows for simultaneously learning a partition and an embedding of a data set.
  We find that without imposing any sparcity constraints, this method learns a sparse decomposition of the latent feature space and the latent cluster space.
  
\end{abstract}

\input{sections/introduction.tex}

\input{sections/methods.tex}

\input{sections/results.tex}

\section{Conclusion}

\input{sections/discussion.tex}

\printbibliography

\input{sections/appendix.tex}

\end{document}
