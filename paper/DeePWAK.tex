\documentclass{article}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}

\usepackage{algorithm2e}


\usepackage{authblk}

\usepackage[backend=biber]{biblatex}
\addbibresource{refs.bib}

\graphicspath{ {./fig/} }

\usepackage{tikz}
\usetikzlibrary{arrows.meta, bending, positioning}

\newcommand{\map}{\mathop{\bigoplus}\limits}
\newcommand{\txtop}[1]{\mathop{\mathtt{#1}}\limits}

\newcommand{\expr}{\txtop{expression}}

\newcommand{\fn}{\txtop{function}}
\newcommand{\tanhl}{\txtop{tanh}}
\newcommand{\linear}{\txtop{linear}}
\newcommand{\sigmoid}{\txtop{sigmoid}}
\newcommand{\argmin}{\txtop{argmin}}
\newcommand{\einsum}{\txtop{einsum}}
\newcommand{\ntos}{\txtop{noise2self}}
\newcommand{\leiden}{\txtop{leiden}}

\newcommand{\encoder}{\txtop{encoder}}
\newcommand{\decoder}{\txtop{decoder}}
\newcommand{\partitioner}{\txtop{partitioner}}

\newcommand{\mathWAK}{\txtop{WAK}}
\newcommand{\mathPWAK}{\txtop{PWAK}}
\newcommand{\mathDEWAKSS}{\txtop{DEWAKSS}}
\newcommand{\mathPart}{\txtop{Partitioner}}
\newcommand{\mathDeePWAK}{\txtop{DeePWAK}}
\newcommand{\mathDeePWAKBlock}{\txtop{DeePWAKBlock}}

\SetKwProg{Fn}{Function}{}{end}
\SetKwProg{Dat}{Data}{}{end}

\SetKwInOut{Hyper}{Hyperparameters}

\SetKwFunction{softmax}{softmax}
\SetKwFunction{MSE}{MSE}
\SetKwFunction{transpose}{transpose}
\SetKwFunction{matmul}{matmul}
\SetKwFunction{eucl}{euclidean}
\SetKwFunction{pca}{pca}
\SetKwFunction{knn}{knn}

\SetKwFunction{sample}{sample}
\SetKwFunction{loss}{loss}
\SetKwFunction{train}{train}

\SetKwFunction{WAK}{WAK}
\SetKwFunction{PWAK}{PWAK}
\SetKwFunction{DEWAKSS}{DEWAKSS}
\SetKwFunction{DeePWAKBlock}{DeePWAKBlock}
\SetKwFunction{DeePWAK}{DeePWAK}

\SetKwFunction{Type}{Type}
\SetKwFunction{List}{List}
\SetKwFunction{Arch}{Arch}
\SetKwFunction{Params}{Params}
\SetKwFunction{Model}{Model}
\SetKwFunction{Linear}{Linear}
\SetKwFunction{Partitioner}{Partitioner}

\date{\today}

\title{Denoising with a Partitioned Affinity Kernel Enables Cluster-Feature Decomposition}

\author[1]{Keira Wiechecki}
\author[2]{Jade Zaslavsky}
\affil[1]{Center for Genomics \& Systems Biology, New York University \\
  \texttt{kaw504@nyu.edu}}
\affil[2]{Transcribbit}

\begin{document}
\maketitle

\begin{abstract}
  We introduce a new method of deep clustering using denoising.
  A denoising-based loss function allows for simultaneously learning a partition and an embedding of a data set.
  We find that without imposing any sparcity constraints, this method learns a sparse decomposition of the latent feature space and the latent cluster space.
  
\end{abstract}

\input{sections/introduction.tex}

\input{sections/methods.tex}

\input{sections/results.tex}

\input{sections/discussion.tex}

\section{Conclusion}

\printbibliography

\input{sections/appendix.tex}

\end{document}
