using Pkg
Pkg.activate("leiden")

using CSV, DataFrames, Tensors, CategoricalArrays, Distributions,
    Flux, LinearAlgebra, SparseArrays, Distances, ProgressMeter, CUDA
using Leiden
using ThreadTools
using JLD2

include("julia/fns.jl")

batchsize = 1024
epochs = 100
Î· = 0.01
Î» = 0

frac = 10
b = 32

ð = 1:32
ð¤ = 1:128
ð›„ = rand(Uniform(0.1,2),128);
ð¬ = 128

dat = (DataFrame âˆ˜ CSV.File)("data/z_dat.csv",normalizenames=true);
dat = (scaledat âˆ˜ Matrix)(dat[:,2:end]);
dat = hcat(filter(x->sum(x) != 0,eachslice(dat,dims=2))...);

n,m = size(dat)
n_Y = Integer(2^round(log2(n) - log2(frac)))
n_X = n - n_Y

tmp = map(_->sampledat(dat',n_Y),1:b);

test = map(x->x[1],tmp);
train = map(x->x[2],tmp);

X = dat' |> gpu;

layers = map(d->Chain(Dense(m => d,relu),Dense(d => m)),ð);

Î˜ = Parallel(vcat,layers...) |> gpu;

loader = Flux.DataLoader((X,repeat(X,outer=(length(ð),1))),batchsize=batchsize,shuffle=true);

opt = Flux.Optimiser(Flux.AdamW(Î·), Flux.WeightDecay(Î»))

@showprogress for _ in 1:epochs
    loss = (X,Y)->Flux.mse(Î˜(X),Y)
    Flux.train!(loss,Flux.params(Î˜),loader,opt)
end

Î˜_s = Flux.state(Î˜|>cpu);
jldsave("models/autoencoder.jld2",Î˜_s=Î˜_s)

Î˜_s = JLD2.load("models/autoencoder.jld2", "Î˜_s");
Flux.loadmodel!(Î˜,Î˜_s);

ð„ = embedding(Î˜,X);
ðƒ = tmap(distmat,ð„);

ðŠ = tmap(ðƒ) do D
    K = sortperm(D,dims=1,rev=true) .% n
    K[K .== 0] .= n
    return K
end;

ðŠ_decomp = tmap(ðŠ) do K
    map(1:maximum(ð¤)) do k
        sparse(1:n,K[:,k],1,n,n)
    end
end;

ð† = tmap(ðŠ_decomp) do K
    map(ð¤) do k
        foldl(+,K[1:k])
    end
end;


L_dk = mapreduce(hcat,Î˜.layers,ð„,ðƒ,ð†) do Î¸,E,D,Gs
    E = E |> gpu
    D = D |> gpu
    map(Gs) do G
        G = G|>gpu
        return ð•ƒ(X,Î¸[2],E,D,G)
    end
end

Tables.table(L_dk) |> CSV.write("data/MSEdk.csv")

k,d = argmin(L_dk).I 

Î¸ = Î˜.layers[d];
E = ð„[d];
D = ðƒ[d];
G = ð†[d][k];
M = wak(D .* G)

Tables.table(E) |> CSV.write("data/E.csv")
Tables.table(G .* D) |> CSV.write("data/G.csv")
Tables.table(M) |> CSV.write("data/M.csv")

ð‚ = tmap(Î³->Leiden.leiden(M,"mod++", Î³ = Î³),ð›„);
(Tables.table âˆ˜ hcat)(ð‚...) |> CSV.write("data/clusters.csv")

ð = map(partitionmat,ð‚)

E = E |> gpu
D = D |> gpu

Láµ§ = map(ð) do P
    P = P |> gpu
    return ð•ƒ(X,Î¸[2],E,D,P)
end
argmin(Láµ§)
nclust = map(maximum,ð‚)
C_df = DataFrame(gamma=ð›„,nclust=nclust,MSE=Láµ§)
C_df |> CSV.write("data/MSEgamma.csv")

G = G |> gpu
L_Î³s = mapreduce(hcat,ð) do P
    P = P |> gpu
    _,L = diffuse(X,Î¸[2],E,D,G,P,ð¬)
    return L
end
s,Î³ = argmin(L_Î³s).I
Tables.table(L_Î³s) |> CSV.write("data/MSEgamma_s.csv")

P = ð[Î³]
Tables.table(P) |> CSV.write("data/P.csv")

ð†_Î³ = tmapmap(G->G .* P,ð†);
L_dkÎ³ = mapreduce(hcat,Î˜.layers,ð„,ðƒ,ð†_Î³) do Î¸,E,D,Gs
    E = E |> gpu
    D = D |> gpu
    map(Gs) do G
        G = G|>gpu
        return ð•ƒ(X,Î¸[2],E,D,G)
    end
end

argmin(L_dkÎ³).I

L_ks = mapreduce(hcat,ð†[d]) do G
    G = G |> gpu
    _,L = diffuse(X,Î¸[2],E,D,G,1,ð¬)
    return L
end
Tables.table(L_ks) |> CSV.write("data/MSEks.csv")
